low_level_predictors = c(2:22)
low_and_high_level_predictors = c(2:29)
setwd("~/h2o-training/tutorials/deeplearning/higgs")
source("helper.R")
best_model <- list()
for (preds in list(low_level_predictors, low_and_high_level_predictors)) {
data = list(x=preds, y=response, train=train_hex, valid=valid_hex, nfolds=2) #helper object
models <- c(
h2o.fit(h2o.glm, data,
list(family="binomial", variable_importances=T, lambda=c(1e-5,1e-4), use_all_factor_levels=T)),
h2o.fit(h2o.randomForest, data,
list(type="fast", importance=TRUE, ntree=c(20), depth=c(10,15))),
h2o.fit(h2o.randomForest, data,
list(type="BigData", importance=TRUE, ntree=c(20), depth=c(10,15))),
h2o.fit(h2o.gbm, data,
list(importance=TRUE, n.tree=c(50), interaction.depth=c(5,10))),
h2o.fit(h2o.deeplearning, data,
list(variable_importances=T, l1=c(1e-5), epochs=10, hidden=list(c(20,20,20), c(100,100))))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
library(h2o)
library(h2o)
h2oServer <- h2o.init()
homedir <- paste0(path.expand("~"),"/h2o/") #modify if needed
TRAIN = "smalldata/adult.gz"
train_hex <- h2o.importFile(h2oServer, path = paste0(homedir,TRAIN), header = F, sep = ',', key = 'train.hex')
summary(train_hex)
train_hex <- h2o.importFile(h2oServer, path = paste0(homedir,TRAIN), header = F, sep = ' ', key = 'train.hex')
summary(train_hex)
predictors = c(1:14)
response = 15
ae_model <- h2o.glm(x=predictors,
y=response,
data=train_hex,
family="binomial",
lambda_search=T)
ae_model
vanilla_model <- h2o.glm(x=predictors,
y=response,
data=train_hex,
family="binomial",
lambda_search=T,
nfold=5)
colnames(train_hex) <- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hours-per-week","native-country")
colnames(train_hex) <- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hours-per-week","native-country","income")
summary(train_hex)
vanilla_model
vanilla_model <- h2o.glm(x=predictors,
y=response,
data=train_hex,
family="binomial",
lambda_search=T,
feature_importances=T,
nfold=5)
vanilla_model <- h2o.glm(x=predictors,
y=response,
data=train_hex,
family="binomial",
lambda_search=T,
feature_importance=T,
nfold=5)
vanilla_model <- h2o.glm(x=predictors, y=response, data=train_hex, family="binomial", lambda_search=T,
variable_importances=T, use_all_factor_levels=T, nfold=5)
vanilla_model
source("helper.R")
random <- h2o.runif(data_hex, seed = 123456789)
data_hex <- h2o.importFile(h2oServer, path = paste0(homedir,TRAIN), header = F, sep = ' ', key = 'data_hex')
colnames(train_hex) <- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hours-per-week","native-country","income")
summary(train_hex)
###### Prepare train/validation/test splits: We split the dataset randomly into 3 pieces. Grid search for hyperparameter tuning and model selection will be done on the training and validation sets, and final model testing is done on the test set. We also assign the resulting frames to meaningful names in the H2O key-value store for later use, and clean up all temporaries at the end.
random <- h2o.runif(data_hex, seed = 123456789)
train_hex <- h2o.assign(data_hex[random < .8,], "train_hex")
valid_hex <- h2o.assign(data_hex[random >= .8 & random < .9,], "valid_hex")
test_hex  <- h2o.assign(data_hex[random >= .9,], "test_hex")
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
######The data consists of 784 (=28^2) pixel values per row, with (gray-scale) values from 0 to 255. The last column is the response (a label in 0,1,2,...,9).
predictors = c(1:14)
response = 15
source("helper.R")
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=3) #helper object
models <- c(
h2o.fit(h2o.glm, data,
list(family="binomial", variable_importances=T, lambda=c(1e-5,1e-4), use_all_factor_levels=T)),
h2o.fit(h2o.randomForest, data,
list(type="fast", importance=TRUE, ntree=c(20), depth=c(10,15))),
h2o.fit(h2o.randomForest, data,
list(type="BigData", importance=TRUE, ntree=c(20), depth=c(10,15))),
h2o.fit(h2o.gbm, data,
list(importance=TRUE, n.tree=c(50), interaction.depth=c(5,10))),
h2o.fit(h2o.deeplearning, data,
list(variable_importances=T, l1=c(1e-5), epochs=10, hidden=list(c(20,20,20), c(100,100))))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
source("helper.R")
#vanilla_model <- h2o.glm(x=predictors, y=response, data=train_hex, family="binomial", lambda_search=T,
#                           variable_importances=T, use_all_factor_levels=T, nfold=5)
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=3) #helper object
models <- c(
h2o.fit(h2o.glm, data,
list(family="binomial", variable_importances=T, lambda=c(1e-5,1e-4), use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data,
list(importance=TRUE, n.tree=c(50), interaction.depth=c(5,10))),
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data,
list(family="binomial", variable_importances=T, lambda_search=T, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data,
list(importance=TRUE, n.tree=c(50), interaction.depth=c(5,10))),
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
source("helper.R")
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE),
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
source("helper.R")
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE),
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
source("helper.R")
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE),
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE)
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE, n.tree=20))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE)),
h2o.fit(h2o.randomForest, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
#h2o.fit(h2o.gbm, data, list(importance=TRUE)),
#h2o.fit(h2o.randomForest, data, list(importance=TRUE)),
h2o.fit(h2o.deeplearning, data, list(variable_importances=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
TRAIN = "smalldata/adult.gz"
data_hex <- h2o.importFile(h2oServer, path = paste0(homedir,TRAIN), header = F, sep = ' ', key = 'data_hex')
colnames(data_hex) <- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hours-per-week","native-country","income")
summary(data_hex)
###### Prepare train/validation/test splits: We split the dataset randomly into 3 pieces. Grid search for hyperparameter tuning and model selection will be done on the training and validation sets, and final model testing is done on the test set. We also assign the resulting frames to meaningful names in the H2O key-value store for later use, and clean up all temporaries at the end.
splitData <- function(data_hex) {
random <- h2o.runif(data_hex, seed = 123456789)
train_hex <- h2o.assign(data_hex[random < .8,], "train_hex")
valid_hex <- h2o.assign(data_hex[random >= .8 & random < .9,], "valid_hex")
test_hex  <- h2o.assign(data_hex[random >= .9,], "test_hex")
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
splitData(data_hex)
data_hex$age <- as.factor(data_hex$age)
splitData(data_hex)
runModel <- function(data_hex) {
splitData(data_hex)
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
runModel(data_hex)
train_hex <- h2o.getFrame(h2oServer, "train_hex")
valid_hex <- h2o.getFrame(h2oServer, "valid_hex")
test_hex <- h2o.getFrame(h2oServer, "test_hex")
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
runModel(data_hex)
h2o.rm(h2oServer, "train_hex")
h2o.rm(h2oServer, "valid_hex")
h2o.rm(h2oServer, "test_hex")
splitData <- function(data_hex) {
random <- h2o.runif(data_hex, seed = 123456789)
h2o.rm(h2oServer, "train_hex")
h2o.rm(h2oServer, "valid_hex")
h2o.rm(h2oServer, "test_hex")
train_hex <- h2o.assign(data_hex[random < .8,], "train_hex")
valid_hex <- h2o.assign(data_hex[random >= .8 & random < .9,], "valid_hex")
test_hex  <- h2o.assign(data_hex[random >= .9,], "test_hex")
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
source("helper.R")
runModel <- function(data_hex) {
splitData(data_hex)
train_hex <- h2o.getFrame(h2oServer, "train_hex")
valid_hex <- h2o.getFrame(h2oServer, "valid_hex")
test_hex <- h2o.getFrame(h2oServer, "test_hex")
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
runModel(data_hex)
data_hex <- h2o.importFile(h2oServer, path = paste0(homedir,TRAIN), header = F, sep = ' ', key = 'data_hex')
h2o.rm(h2oServer, "data_hex")
data_hex <- h2o.importFile(h2oServer, path = paste0(homedir,TRAIN), header = F, sep = ' ', key = 'data_hex')
colnames(data_hex) <- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hours-per-week","native-country","income")
summary(data_hex)
###### Prepare train/validation/test splits: We split the dataset randomly into 3 pieces. Grid search for hyperparameter tuning and model selection will be done on the training and validation sets, and final model testing is done on the test set. We also assign the resulting frames to meaningful names in the H2O key-value store for later use, and clean up all temporaries at the end.
splitData <- function(data_hex) {
random <- h2o.runif(data_hex, seed = 123456789)
h2o.rm(h2oServer, "train_hex")
h2o.rm(h2oServer, "valid_hex")
h2o.rm(h2oServer, "test_hex")
train_hex <- h2o.assign(data_hex[random < .8,], "train_hex")
valid_hex <- h2o.assign(data_hex[random >= .8 & random < .9,], "valid_hex")
test_hex  <- h2o.assign(data_hex[random >= .9,], "test_hex")
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
######Yada
predictors = c(1:14)
response = 15
### Build a model without feature engineering
####1. Vanilla GLM model
######Yada
source("helper.R")
runModel <- function(data_hex) {
splitData(data_hex)
train_hex <- h2o.getFrame(h2oServer, "train_hex")
valid_hex <- h2o.getFrame(h2oServer, "valid_hex")
test_hex <- h2o.getFrame(h2oServer, "test_hex")
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
runModel(data_hex)
library(h2o)
h2oServer <- h2o.init()
homedir <- paste0(path.expand("~"),"/h2o/") #modify if needed
TRAIN = "smalldata/adult.gz"
data_hex <- h2o.importFile(h2oServer, path = paste0(homedir,TRAIN), header = F, sep = ' ', key = 'data_hex')
colnames(data_hex) <- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hours-per-week","native-country","income")
summary(data_hex)
###### Prepare train/validation/test splits: We split the dataset randomly into 3 pieces. Grid search for hyperparameter tuning and model selection will be done on the training and validation sets, and final model testing is done on the test set. We also assign the resulting frames to meaningful names in the H2O key-value store for later use, and clean up all temporaries at the end.
splitData <- function(data_hex) {
random <- h2o.runif(data_hex, seed = 123456789)
h2o.rm(h2oServer, "train_hex")
h2o.rm(h2oServer, "valid_hex")
h2o.rm(h2oServer, "test_hex")
train_hex <- h2o.assign(data_hex[random < .8,], "train_hex")
valid_hex <- h2o.assign(data_hex[random >= .8 & random < .9,], "valid_hex")
test_hex  <- h2o.assign(data_hex[random >= .9,], "test_hex")
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
######Yada
predictors = c(1:14)
response = 15
### Build a model without feature engineering
####1. Vanilla GLM model
######Yada
source("helper.R")
runModel <- function(data_hex) {
splitData(data_hex)
train_hex <- h2o.getFrame(h2oServer, "train_hex")
valid_hex <- h2o.getFrame(h2oServer, "valid_hex")
test_hex <- h2o.getFrame(h2oServer, "test_hex")
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
runModel(data_hex)
splitData(data_hex)
h2o.rm(h2oServer, "train_hex")
splitData <- function(data_hex) {
random <- h2o.runif(data_hex, seed = 123456789)
train_hex <- h2o.assign(data_hex[random < .8,], "train_hex")
valid_hex <- h2o.assign(data_hex[random >= .8 & random < .9,], "valid_hex")
test_hex  <- h2o.assign(data_hex[random >= .9,], "test_hex")
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
source("helper.R")
runModel <- function(data_hex) {
splitData(data_hex)
train_hex <- h2o.getFrame(h2oServer, "train_hex")
valid_hex <- h2o.getFrame(h2oServer, "valid_hex")
test_hex <- h2o.getFrame(h2oServer, "test_hex")
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
runModel(data_hex)
train_hex <- h2o.getFrame(h2oServer, "train_hex")
valid_hex <- h2o.getFrame(h2oServer, "valid_hex")
test_hex <- h2o.getFrame(h2oServer, "test_hex")
runModel <- function(data_hex) {
splitData(data_hex)
train_hex <- h2o.getFrame(h2oServer, "train_hex")
valid_hex <- h2o.getFrame(h2oServer, "valid_hex")
test_hex <- h2o.getFrame(h2oServer, "test_hex")
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
runModel(data_hex)
library(h2o)
h2oServer <- h2o.init()
homedir <- paste0(path.expand("~"),"/h2o/") #modify if needed
TRAIN = "smalldata/adult.gz"
data_hex <- h2o.importFile(h2oServer, path = paste0(homedir,TRAIN), header = F, sep = ' ', key = 'data_hex')
colnames(data_hex) <- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hours-per-week","native-country","income")
summary(data_hex)
splitData <- function(data_hex) {
random <- h2o.runif(data_hex, seed = 123456789)
train_hex <- h2o.assign(data_hex[random < .8,], "train_hex")
valid_hex <- h2o.assign(data_hex[random >= .8 & random < .9,], "valid_hex")
test_hex  <- h2o.assign(data_hex[random >= .9,], "test_hex")
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
predictors = c(1:14)
response = 15
### Build a model without feature engineering
####1. Vanilla GLM model
######Yada
source("helper.R")
runModel <- function(data_hex) {
splitData(data_hex)
train_hex <- h2o.getFrame(h2oServer, "train_hex")
valid_hex <- h2o.getFrame(h2oServer, "valid_hex")
test_hex <- h2o.getFrame(h2oServer, "test_hex")
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda_search=F, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
runModel(data_hex)
data_hex$age <- as.factor(data_hex$age)
runModel(data_hex)
runModel <- function(data_hex) {
splitData(data_hex)
train_hex <- h2o.getFrame(h2oServer, "train_hex")
valid_hex <- h2o.getFrame(h2oServer, "valid_hex")
test_hex <- h2o.getFrame(h2oServer, "test_hex")
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda=1e-5, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
runModel(data_hex)
summary(data_hex)
data_hex$capital-gain <- as.factor(data_hex$capital-gain)
data_hex$'capital-gain' <- as.factor(data_hex$'capital-gain')
summary(data_hex)
data_hex$'capital-loss' <- as.factor(data_hex$'capital-loss')
summary(data_hex)
runModel(data_hex)
data_hex$'hours-per-week' <- as.factor(data_hex$'hours-per-week')
summary(data_hex)
runModel(data_hex)
factor_interactions <- h2o.interaction(data_hex, factors = predictors, pairwise = TRUE, max_factors = 1000, min_occurrence = 1)
factor_interactions <- h2o.interaction(data_hex, factors = predictors[-2], pairwise = TRUE, max_factors = 1000, min_occurrence = 1)
predictors
predictors[-3]
factor_interactions <- h2o.interaction(data_hex, factors = predictors[-3], pairwise = TRUE, max_factors = 1000, min_occurrence = 1)
factor_interactions <- h2o.interaction(data_hex, factors = predictors[-3,-5], pairwise = TRUE, max_factors = 1000, min_occurrence = 1)
factor_interactions <- h2o.interaction(data_hex, factors = predictors[-c(3,5)], pairwise = TRUE, max_factors = 1000, min_occurrence = 1)
data_hex <- cbind(data_hex, factor_interactions)
summary(data_hex)
runModel(data_hex)
summary(train_hex)
data = list(x=colnames(data_hex)[-response], y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
runModel <- function(data_hex) {
splitData(data_hex)
train_hex <- h2o.getFrame(h2oServer, "train_hex")
valid_hex <- h2o.getFrame(h2oServer, "valid_hex")
test_hex <- h2o.getFrame(h2oServer, "test_hex")
best_model <- list()
data = list(x=colnames(data_hex)[-response], y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda=1e-5, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
runModel(data_hex)
colnames(data_hex)[-response]
colnames(data_hex)
colnames(data_hex)[-response]
colnames(data_hex)
summary(data_hex)
data_hex
library(h2o)
h2oServer <- h2o.init()
homedir <- paste0(path.expand("~"),"/h2o/") #modify if needed
TRAIN = "smalldata/adult.gz"
data_hex <- h2o.importFile(h2oServer, path = paste0(homedir,TRAIN), header = F, sep = ' ', key = 'data_hex')
colnames(data_hex) <- c("age","workclass","fnlwgt","education","education-num","marital-status","occupation","relationship","race","sex","capital-gain","capital-loss","hours-per-week","native-country","income")
summary(data_hex)
###### Prepare train/validation/test splits: We split the dataset randomly into 3 pieces. Grid search for hyperparameter tuning and model selection will be done on the training and validation sets, and final model testing is done on the test set. We also assign the resulting frames to meaningful names in the H2O key-value store for later use, and clean up all temporaries at the end.
splitData <- function(data_hex) {
random <- h2o.runif(data_hex, seed = 123456789)
train_hex <- h2o.assign(data_hex[random < .8,], "train_hex")
valid_hex <- h2o.assign(data_hex[random >= .8 & random < .9,], "valid_hex")
test_hex  <- h2o.assign(data_hex[random >= .9,], "test_hex")
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
######Yada
response = 15
### Build a model without feature engineering
####1. Vanilla GLM model
######Yada
source("helper.R")
runModel <- function(data_hex) {
splitData(data_hex)
train_hex <- h2o.getFrame(h2oServer, "train_hex")
valid_hex <- h2o.getFrame(h2oServer, "valid_hex")
test_hex <- h2o.getFrame(h2oServer, "test_hex")
best_model <- list()
data = list(x=colnames(data_hex)[-response], y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda=1e-5, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
data_hex$age <- as.factor(data_hex$age)
runModel <- function(data_hex) {
splitData(data_hex)
train_hex <- h2o.getFrame(h2oServer, "train_hex")
valid_hex <- h2o.getFrame(h2oServer, "valid_hex")
test_hex <- h2o.getFrame(h2oServer, "test_hex")
predictors <- colnames(data_hex)[-response]
best_model <- list()
data = list(x=predictors, y=response, train=train_hex, valid=valid_hex, nfolds=5) #helper object
models <- c(
h2o.fit(h2o.glm, data, list(family="binomial", variable_importances=T, lambda=1e-5, use_all_factor_levels=T)),
h2o.fit(h2o.gbm, data, list(importance=TRUE))
)
best_model <- list(best_model, h2o.leaderBoard(models, test_hex, response))
h2o.rm(h2oServer, grep(pattern = "Last.value", x = h2o.ls(h2oServer)$Key, value = TRUE))
}
runModel(data_hex)
